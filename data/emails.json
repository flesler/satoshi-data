[
	{
		"date": "2008-11-03 01:37:43",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014815.html",
		"q": "We very, very much need such a system, but the way I understand your proposal, it does not seem to scale to the required size.\nFor transferable proof of work tokens to have value, they must have monetary value. To have monetary value, they must be transferred within a very large network - for example a file trading network akin to bittorrent.\nTo detect and reject a double spending event in a timely manner, one must have most past transactions of the coins in the transaction, which,\nnaively implemented, requires each peer to have most past transactions, or most past transactions that occurred recently. If hundreds of millions of people are doing transactions, that is a lot of",
		"a": "Long before the network gets anywhere near as large as that, it would be safe for users to use Simplified Payment Verification (section 8) to check for double spending, which only requires having the chain of block headers, or about 12KB per day. Only people trying to create new coins would need to run network nodes. At first, most users would run network nodes, but as the network grows beyond a certain point, it would be left more and more to specialists with server farms of specialized hardware. A server farm would only need to have one node on the network and the rest of the LAN connects with that one node.\nThe bandwidth might not be as prohibitive as you think. A typical transaction would be about 400 bytes (ECC is nicely compact). Each transaction has to be broadcast twice, so lets say 1KB per transaction. Visa processed 37 billion transactions in FY2008, or an average of 100 million transactions per day. That many transactions would take 100GB of bandwidth, or the size of 12 DVD or 2 HD quality movies, or about $18 worth of bandwidth at current prices.\nIf the network were to get that big, it would take several years, and by then, sending 2 HD movies over the Internet would probably not seem like a big deal."
	},
	{
		"date": "2008-11-03 16:23:49",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014818.html",
		"q": "But they don't. Bad guys routinely control zombie farms of 100,000 machines or more. People I know who run a blacklist of spam sending zombies tell me they often see a million new zombies a day.\nThis is the same reason that hashcash can't work on today's Internet\n-- the good guys have vastly less computational firepower than the bad guys.\nI also have my doubts about other issues, but this one is the killer.\nR's,",
		"a": "Thanks for bringing up that point.\nI didn't really make that statement as strong as I could have. The requirement is that the good guys collectively have more CPU power than any single attacker.\nThere would be many smaller zombie farms that are not big enough to overpower the network, and they could still make money by generating bitcoins. The smaller farms are then the \"honest nodes\". (I need a better term than \"honest\") The more smaller farms resort to generating bitcoins, the higher the bar gets to overpower the network, making larger farms also too small to overpower it so that they may as well generate bitcoins too. According to the \"long tail\" theory, the small, medium and merely large farms put together should add up to a lot more than the biggest zombie farm.\nEven if a bad guy does overpower the network, it's not like he's instantly rich. All he can accomplish is to take back money he himself spent, like bouncing a check. To exploit it, he would have to buy something from a merchant, wait till it ships, then overpower the network and try to take his money back. I don't think he could make as much money trying to pull a carding scheme like that as he could by generating bitcoins. With a zombie farm that big, he could generate more bitcoins than everyone else combined.\nThe Bitcoin network might actually reduce spam by diverting zombie farms to generating bitcoins instead."
	},
	{
		"date": "2008-11-06 20:15:40",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014823.html",
		"q": "If I understand Simplified Payment Verification correctly:\nNew coin issuers need to store all coins and all recent coin transfers.\nThere are many new coin issuers, as many as want to be issuers, but far more coin users.\nOrdinary entities merely transfer coins. To see if a coin transfer is OK, they report it to one or more new coin issuers and see if the new coin issuer accepts it.\nNew coin issuers check transfers of old coins so that their new coins have valid form, and they report the outcome of this check so that people will report their transfers to the new coin issuer.\nIf someone double spends a coin, and one expenditure is reported to one new coin issuer, and the other simultaneously reported to another new coin issuer, then both issuers to swifly agree on a unique sequence order of payments. This, however, is a non trivial problem of a massively distributed massive database, a notoriously tricky problem, for which there are at present no peer to peer solutions. Obiously it is a solvable problem,\npeople solve it all the time, but not an easy problem.\nPeople fail to solve it rather more frequently.\nBut let us suppose that the coin issue network is dominated by a small number of issuers as seems likely.\nIf a small number of entities are issuing new coins,\nthis is more resistant to state attack that with a single issuer, but the government regularly attacks financial networks, with the financial collapse ensuing from the most recent attack still under way as I write this.\nGovernment sponsored enterprises enter the business, in due course bad behavior is made mandatory, and the evil financial network is bigger than the honest financial network, with the result that even though everyone knows what is happening, people continue to use the paper issued by the evil financial network, because of network effects - the big, main issuers, are the issuers you use if you want to do business.\nThen knowledgeable people complain that the evil financial network is heading for disaster, that the government sponsored enterprises are about to cause a\n\"collapse of the total financial system\", as Wallison and Alan Greenspan complained in 2005, the government debates shrinking the evil government sponsored enterprises, as with \"S. 190 [109th]: Federal Housing\nEnterprise Regulatory Reform Act of 2005\" but they find easy money too seductive, and S. 190 goes down in flames before a horde of political activists chanting that easy money is sound, and opposing it is racist, nazi,\nignorant, and generally hateful, the recent S. 190 debate on limiting portfolios (bond issue supporting dud mortgages) by government sponsored enterprises being a perfect reprise of the debates on limiting the issue of new assignats in the 1790s.\nThe big and easy government attacks on money target a single central money issuer, as with the first of the modern political attacks, the French Assignat of 1792,\nbut in the late nineteenth century political attacks on financial networks began, as for example the Federal reserve act of 1913, the goal always being to wind up the network into a single too big to fail entity, and they have been getting progressively bigger, more serious, and more disastrous, as with the most recent one. Each attack is hugely successful, and after the cataclysm that the attack causes the attackers are hailed as saviors of the poor, the oppressed, and the nation generally, and the blame for the the bad consequences is dumped elsewhere, usually on Jews,\ngreedy bankers, speculators, etc, because such attacks are difficult for ordinary people understand. I have trouble understanding your proposal - ordinary users will be easily bamboozled by a government sponsored security update. Further, when the crisis hits, to disagree with the line, to doubt that the regulators are right, and the problem is the evil speculators, becomes political suicide, as it did in America in 2007,\nsometimes physical suicide, as in Weimar Germany.\nStill, it is better, and more resistant to attack by government sponsored enterprises, than anything I have seen so far.\nIf there were a hundred or a thousand money issuers by the time the government attacks, the kind of government attacks on financial networks that we have recently seen might well be more difficult.\nBut I think we need to concern ourselves with minimizing the data and bandwidth required by money issuers - for small coins, the protocol seems wasteful. It would be nice to have the full protocol for big coins, and some shortcut for small coins wherein people trust account based money for small amounts till they get wrapped up into big coins.\nThe smaller the data storage and bandwidth required for money issuers, the more resistant the system is the kind of government attacks on financial networks that we have",
		"a": "Yes, but we can win a major battle in the arms race and gain a new territory of freedom for several years.\nGovernments are good at cutting off the heads of a centrally controlled networks like Napster, but pure P2P networks like Gnutella and Tor seem to be holding their own."
	},
	{
		"date": "2008-11-08 18:54:38",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014831.html",
		"q": "I think the real issue with this system is the market for bitcoins.\nComputing proofs-of-work have no intrinsic value. We can have a limited supply curve (although the \"currency\"\nis inflationary at about 35% as that's how much faster computers get annually) but there is no demand curve that intersects it at a positive price point.\nI know the same (lack of intrinsic value) can be said of fiat currencies, but an artificial demand for fiat currencies is created by (among other things) taxation and legal-tender laws. Also, even a fiat currency can be an inflation hedge against another fiat currency's higher rate of inflation. But in the case of bitcoins the inflation rate of 35% is almost guaranteed by the technology, there are no supporting mechanisms for taxation, and no legal-tender laws. People will not hold assets in this highly-inflationary currency if they can help it.",
		"a": "Increasing hardware speed is handled: \"To compensate for increasing hardware speed and varying interest in running nodes over time, the proof-of-work difficulty is determined by a moving average targeting an average number of blocks per hour. If they're generated too fast, the difficulty increases.\"\nAs computers get faster and the total computing power applied to creating bitcoins increases, the difficulty increases proportionally to keep the total new production constant. Thus, it is known in advance how many new bitcoins will be created every year in the future.\nThe fact that new coins are produced means the money supply increases by a planned amount, but this does not necessarily result in inflation. If the supply of money increases at the same rate that the number of people using it increases, prices remain stable. If it does not increase as fast as demand, there will be deflation and early holders of money will see its value increase.\nCoins have to get initially distributed somehow, and a constant rate seems like the best formula."
	},
	{
		"date": "2008-11-09 01:58:48",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014832.html",
		"q": "Bitcoin seems to be a very promising idea. I like the idea of basing security on the assumption that the CPU power of honest participants outweighs that of the attacker. It is a very modern notion that exploits the power of the long tail. When Wikipedia started I never thought it would work, but it has proven to be a great success for some of the same reasons.\nI also do think that there is potential value in a form of unforgeable token whose production rate is predictable and can't be influenced by corrupt parties. This would be more analogous to gold than to fiat currencies. Nick Szabo wrote many years ago about what he called \"bit gold\"[1] and this could be an implementation of that concept. There have also been proposals for building light-weight anonymous payment schemes on top of heavy-weight non-anonymous systems, so Bitcoin could be leveraged to allow for anonymity even beyond the mechanisms discussed in the paper.\nUnfortunately I am having trouble fully understanding the system. The paper describes key concepts and some data structures, but does not clearly specify the various rules and verifications that the participants in the system would have to follow.\nIn particular I don't understand exactly what verifications P2P nodes perform when they receive new blocks from other nodes, and how they handle transactions that have been broadcast to them. For example, it is mentioned that if a broadcast transaction does not reach all nodes,\nit is OK, as it will get into the block chain before long. How does this happen - what if the node that creates the \"next\" block (the first node to find the hashcash collision) did not hear about the transaction,\nand then a few more blocks get added also by nodes that did not hear about that transaction? Do all the nodes that did hear it keep that transaction around, hoping to incorporate it into a block once they get lucky enough to be the one which finds the next collision?\nOr for example, what if a node is keeping two or more chains around as it waits to see which grows fastest, and a block comes in for chain A\nwhich would include a double-spend of a coin that is in chain B? Is that checked for or not? (This might happen if someone double-spent and two different sets of nodes heard about the two different transactions with the same coin.)\nThis kind of data management, and the rules for handling all the packets that are flowing around is largely missing from the paper.\nI also don't understand exactly how double-spending, or cancelling transactions, is accomplished by a superior attacker who is able to muster more computing power than all the honest participants. I see that he can create new blocks and add them to create the longest chain, but how can he erase or add old transactions in the chain? As the attacker sends out his new blocks, aren't there consistency checks which honest nodes can perform, to make sure that nothing got erased? More explanation of this attack would be helpful, in order to judge the gains to an attacker from this, versus simply using his computing power to mint new coins honestly.\nAs far as the spending transactions, what checks does the recipient of a coin have to perform? Does she need to go back through the coin's entire history of transfers, and make sure that every transaction on the list is indeed linked into the \"timestamp\" block chain? Or can she just do the latest one? Do the timestamp nodes check transactions, making sure that the previous transaction on a coin is in the chain, thereby enforcing the rule that all transactions in the chain represent valid coins?\nSorry about all the questions, but as I said this does seem to be a very promising and original idea, and I am looking forward to seeing how the concept is further developed. It would be helpful to see a more process oriented description of the idea, with concrete details of the data structures for the various objects (coins, blocks, transactions),\nthe data which is included in messages, and algorithmic descriptions of the procedures for handling the various events which would occur in this system. You mentioned that you are working on an implementation,\nbut I think a more formal, text description of the system would be a helpful next step.\nHal Finney",
		"a": "Right, nodes keep transactions in their working set until they get into a block. If a transaction reaches 90% of nodes, then each time a new block is found, it has a 90% chance of being in it.\nThat does not need to be checked for. The transaction in whichever branch ends up getting ahead becomes the valid one, the other is invalid. If someone tries to double spend like that, one and only one spend will always become valid, the others invalid.\nReceivers of transactions will normally need to hold transactions for perhaps an hour or more to allow time for this kind of possibility to be resolved. They can still re-spend the coins immediately, but they should wait before taking an action such as shipping goods.\nThe attacker isn't adding blocks to the end. He has to go back and redo the block his transaction is in and all the blocks after it, as well as any new blocks the network keeps adding to the end while he's doing that. He's rewriting history. Once his branch is longer, it becomes the new valid one.\nThis touches on a key point. Even though everyone present may see the shenanigans going on, there's no way to take advantage of that fact.\nIt is strictly necessary that the longest chain is always considered the valid one. Nodes that were present may remember that one branch was there first and got replaced by another, but there would be no way for them to convince those who were not present of this. We can't have subfactions of nodes that cling to one branch that they think was first, others that saw another branch first, and others that joined later and never saw what happened. The CPU power proof-of-work vote must have the final say. The only way for everyone to stay on the same page is to believe that the longest chain is always the valid one, no matter what.\nThe recipient just needs to verify it back to a depth that is sufficiently far back in the block chain, which will often only require a depth of 2 transactions. All transactions before that can be discarded.\nRight, exactly. When a node receives a block, it checks the signatures of every transaction in it against previous transactions in blocks. Blocks can only contain transactions that depend on valid transactions in previous blocks or the same block. Transaction C could depend on transaction B in the same block and B depends on transaction A in an earlier block.\nI appreciate your questions. I actually did this kind of backwards. I had to write all the code before I could convince myself that I could solve every problem, then I wrote the paper. I think I will be able to release the code sooner than I could write a detailed spec. You're already right about most of your assumptions where you filled in the blanks."
	},
	{
		"date": "2008-11-09 03:09:49",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014833.html",
		"q": "Yes, but we can win a major battle in the arms race and gain a new territory of freedom for several years.\nGovernments are good at cutting off the heads of a centrally controlled networks like Napster, but pure P2P networks like Gnutella and Tor seem to be holding their own.",
		"a": "The proof-of-work chain is the solution to the synchronisation problem, and to knowing what the globally shared view is without having to trust anyone.\nA transaction will quickly propagate throughout the network, so if two versions of the same transaction were reported at close to the same time, the one with the head start would have a big advantage in reaching many more nodes first. Nodes will only accept the first one they see, refusing the second one to arrive, so the earlier transaction would have many more nodes working on incorporating it into the next proof-of-work. In effect, each node votes for its viewpoint of which transaction it saw first by including it in its proof-of-work effort.\nIf the transactions did come at exactly the same time and there was an even split, it's a toss up based on which gets into a proof-of-work first, and that decides which is valid.\nWhen a node finds a proof-of-work, the new block is propagated throughout the network and everyone adds it to the chain and starts working on the next block after it. Any nodes that had the other transaction will stop trying to include it in a block, since it's now invalid according to the accepted chain.\nThe proof-of-work chain is itself self-evident proof that it came from the globally shared view. Only the majority of the network together has enough CPU power to generate such a difficult chain of proof-of-work. Any user, upon receiving the proof-of-work chain, can see what the majority of the network has approved. Once a transaction is hashed into a link that's a few links back in the chain, it is firmly etched into the global history."
	},
	{
		"date": "2008-11-09 16:31:26",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014838.html",
		"q": "The proof-of-work chain is the solution to the synchronisation problem, and to knowing what the globally shared view is without having to trust anyone.\nA transaction will quickly propagate throughout the network, so if two versions of the same transaction were reported at close to the same time, the one with the head start would have a big advantage in reaching many more nodes first. Nodes will only accept the first one they see, refusing the second one to arrive, so the earlier transaction would have many more nodes working on incorporating it into the next proof-of-work. In effect, each node votes for its viewpoint of which transaction it saw first by including it in its proof-of-work effort.\nIf the transactions did come at exactly the same time and there was an even split, it's a toss up based on which gets into a proof-of-work first, and that decides which is valid.\nWhen a node finds a proof-of-work, the new block is propagated throughout the network and everyone adds it to the chain and starts working on the next block after it. Any nodes that had the other transaction will stop trying to include it in a block, since it's now invalid according to the accepted chain.\nThe proof-of-work chain is itself self-evident proof that it came from the globally shared view. Only the majority of the network together has enough CPU power to generate such a difficult chain of proof-of-work. Any user, upon receiving the proof-of-work chain, can see what the majority of the network has approved. Once a transaction is hashed into a link that's a few links back in the chain, it is firmly etched into the global history.",
		"a": "They both broadcast their blocks. All nodes receive them and keep both, but only work on the one they received first. We'll suppose exactly half received one first, half the other.\nIn a short time, all the transactions will finish propagating so that everyone has the full set. The nodes working on each side will be trying to add the transactions that are missing from their side. When the next proof-of-work is found, whichever previous block that node was working on, that branch becomes longer and the tie is broken. Whichever side it is, the new block will contain the other half of the transactions, so in either case, the branch will contain all transactions. Even in the unlikely event that a split happened twice in a row, both sides of the second split would contain the full set of transactions anyway.\nIt's not a problem if transactions have to wait one or a few extra cycles to get into a block."
	},
	{
		"date": "2008-11-10 02:14:30",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014842.html",
		"q": "This does not work - your proposal involves complications I do not think you have thought through.\nFurthermore, it cannot be made to work, as in the proposed system the work of tracking who owns what coins is paid for by seigniorage, which requires inflation.\nThis is not an intolerable flaw - predictable inflation is less objectionable than inflation that gets jiggered around from time to time to transfer wealth from one",
		"a": "If you're having trouble with the inflation issue, it's easy to tweak it for transaction fees instead. It's as simple as this: let the output value from any transaction be 1 cent less than the input value. Either the client software automatically writes transactions for 1 cent more than the intended payment value, or it could come out of the payee's side. The incentive value when a node finds a proof-of-work for a block could be the total of the fees in the block."
	},
	{
		"date": "2008-11-10 22:18:20",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014843.html",
		"q": "--\nSo what happened to the coin that lost the race?\nOn the one hand, we want people who make coins to be motivated to keep and record all transactions, and obtain an up to date record of all transactions in a timely manner. On the other hand, it is a bit harsh if the guy who came second is likely to lose his coin.\nFurther, your description of events implies restrictions on timing and coin generation - that the entire network generates coins slowly compared to the time required for news of a new coin to flood the network, otherwise the chains diverge more and more, and no one ever knows which chain is the winner.\nYou need to make these restrictions explicit, for network flood time may well be quite slow.\nWhich implies that the new coin rate is slower.\nWe want spenders to have certainty that their transaction is valid at the time it takes a spend to flood the network, not at the time it takes for branch races to be resolved.\nAt any given time, for example at 1 040 689 138 seconds we can look back at the past and say:\nAt 1 040 688 737 seconds, node 5 was *it*, and he incorporated all the coins he had discovered into the chain, and all the new transactions he knew about on top of the previous link\nAt 1 040 688 792 seconds, node 2 was *it*, and he incorporated all the coins he had discovered into the chain, and all the new transactions he knew about into the chain on top of node 5's link.\nAt 1 040 688 745 seconds, node 7 was *it*, and he incorporated all the coins he had discovered into the chain, and all the new transactions he knew about into the chain on top of node 2's link.\nBut no one can know who is *it* right now\nSo how does one know when to reveal one's coins? One solution is that one does not. One incorporates a hash of the coin secret whenever one thinks one might be\n*it*, and after that hash is securely in the chain,\nafter one knows that one was *it* at the time, one can then safely spend the coin that one has found, revealing the secret.\nThis solution takes care of the coin revelation problem,\nbut does not solve the spend recording problem. If one node is ignoring all spends that it does not care about,\nit suffers no adverse consequences. We need a protocol in which your prospects of becoming *it* also depend on being seen by other nodes as having a reasonably up to date and complete list of spends - which this protocol",
		"a": "When there are multiple double-spent versions of the same transaction, one and only one will become valid.\nThe receiver of a payment must wait an hour or so before believing that it's valid. The network will resolve any possible double-spend races by then.\nThe guy who received the double-spend that became invalid never thought he had it in the first place. His software would have shown the transaction go from \"unconfirmed\" to \"invalid\". If necessary, the UI can be made to hide transactions until they're sufficiently deep in the block chain.\nSorry if I didn't make that clear. The target time between blocks will probably be 10 minutes.\nEvery block includes its creation time. If the time is off by more than 36 hours, other nodes won't work on it. If the timespan over the last 6*24*30 blocks is less than 15 days, blocks are being generated too fast and the proof-of-work difficulty doubles. Everyone does the same calculation with the same chain data, so they all get the same result at the same link in the chain.\nInstantant non-repudiability is not a feature, but it's still much faster than existing systems. Paper cheques can bounce up to a week or two later. Credit card transactions can be contested up to 60 to 180 days later. Bitcoin transactions can be sufficiently irreversible in an hour or two.\nWith the transaction fee based incentive system I recently posted, nodes would have an incentive to include all the paying transactions they receive."
	},
	{
		"date": "2008-11-13 22:56:55",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014849.html",
		"q": "That is not the question I am asking.\nIt is not trust that worries me, it is how it is possible to have a a globally shared view even if everyone is well behaved.\nThe process for arriving at a globally shared view of who owns what bitgold coins is insufficiently specified.\nOnce specified, then we can start considering whether everyone has incentives to behave correctly.\nIt is not sufficient that everyone knows X. We also need everyone to know that everyone knows X, and that everyone knows that everyone knows that everyone knows X\n- which, as in the Byzantine Generals problem, is the classic hard problem of distributed data processing.\nThis problem becomes harder when X is quite possibly a very large amount of data - agreement on who was the owner of every bitgold coin at such and such a time.\nAnd then on top of that we need everyone to have a motive to behave in such a fashion that agreement arises. I cannot see that they have motive when I do not know the behavior to be motivated.\nYou keep repeating your analysis of the system under attack. We cannot say how the system will behave under attack until we know how the system is supposed to behave when not under attack.\nIf there are a lot of transactions, it is hard to efficiently discover the discrepancies between one node's view and another node's view, and because new transactions are always arriving, no two nodes will ever have the same view, even if all nodes are honest, and all reported transactions are correct and true single spends.\nWe should be able to accomplish a system where two nodes are likely to come to agreement as to who owned what bitgold coins at some very recent past time, but it is not simple to do so.\nIf one node constructs a hash that represents its knowledge of who owned what bitgold coins at a particular time, and another node wants to check that hash, it is not simple to do it in such a way that agreement is likely, and disagreement between honest well behaved nodes is efficiently detected and efficiently resolved.\nAnd if we had a specification of how agreement is generated, it is not obvious why the second node has incentive to check that hash.\nThe system has to work in such a way that nodes can easily and cheaply change their opinion about recent transactions, so as to reach consensus, but in order to provide finality and irreversibility, once consensus has been reached, and then new stuff has be piled on top of old consensus, in particular new bitgold has been piled on top of old consensus, it then becomes extremely difficult to go back and change what was decided.\nSaying that is how it works, does not give us a method to make it work that way.\nYou keep discussing attacks. I find it hard to think about response to attack when it is not clear to me what normal behavior is in the case of good conduct by each and every party.\nDistributed databases are *hard* even when all the databases perfectly follow the will of a single owner.\nMessages get lost, links drop, syncrhonization delays become abnormal, and entire machines go up in flames,\nand the network as a whole has to take all this in its stride.\nFiguring out how to do this is hard, even in the complete absence of attacks. Then when we have figured",
		"a": "The proof-of-work chain is a solution to the Byzantine Generals' Problem. I'll try to rephrase it in that context.\nA number of Byzantine Generals each have a computer and want to attack the King's wi-fi by brute forcing the password, which they've learned is a certain number of characters in length. Once they stimulate the network to generate a packet, they must crack the password within a limited time to break in and erase the logs, otherwise they will be discovered and get in trouble. They only have enough CPU power to crack it fast enough if a majority of them attack at the same time.\nThey don't particularly care when the attack will be, just that they all agree. It has been decided that anyone who feels like it will announce a time, and whatever time is heard first will be the official attack time. The problem is that the network is not instantaneous, and if two generals announce different attack times at close to the same time, some may hear one first and others hear the other first.\nThey use a proof-of-work chain to solve the problem. Once each general receives whatever attack time he hears first, he sets his computer to solve an extremely difficult proof-of-work problem that includes the attack time in its hash. The proof-of-work is so difficult, it's expected to take 10 minutes of them all working at once before one of them finds a solution. Once one of the generals finds a proof-of-work, he broadcasts it to the network, and everyone changes their current proof-of-work computation to include that proof-of-work in the hash they're working on. If anyone was working on a different attack time, they switch to this one, because its proof-of-work chain is now longer.\nAfter two hours, one attack time should be hashed by a chain of 12 proofs-of-work. Every general, just by verifying the difficulty of the proof-of-work chain, can estimate how much parallel CPU power per hour was expended on it and see that it must have required the majority of the computers to produce that much proof-of-work in the allotted time. They had to all have seen it because the proof-of-work is proof that they worked on it. If the CPU power exhibited by the proof-of-work chain is sufficient to crack the password, they can safely attack at the agreed time."
	},
	{
		"date": "2008-11-14 18:55:35",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014853.html",
		"q": "I agree that the description is not completely clear on how these matters are handled. Satoshi has suggested that releasing source code may be the best way to clarify the design. As I have tried to work through details on my own, it does appear that the rules become rather complicated and indeed one needs at least a pseudo-code algorithm to specify the behavior. So perhaps writing real code is not a bad way to go. I found that there is a sourceforge project set up for bitgold, although it does not have any code yet.\nIn answer to James' specific question, about what happens when different nodes see different sets of transactions, due to imperfect broadcast, here is how I understand it. Each node must be prepared to maintain potentially several \"candidate\" block chains, each of which may eventually turn out to become the longest one, the one which wins. Once a given block chain becomes sufficiently longer than a competitor, the shorter one can be deleted. This length differential is a parameter which depends on the node's threat model for how much compute power an attacker can marshall,\nin terms of the fraction of the \"honst\" P2P network's work capacity,\nand is estimated in the paper. The idea is that once a chain gets far enough behind the longest one, there is essentially no chance that it can ever catch up.\nIn order to resolve the issue James raised, I think it is necessary that nodes keep a separate pending-transaction list associated with each candidate chain. This list would include all transactions the node has received (via broadcast by the transactees) but which have not yet been incorporated into that block chain. At any given time, the node is working to extend the longest block chain, and the block it is working to find a hash collision for will include all of the pending transactions associated with that chain.\nI think that this way, when a candidate chain is deleted because it got too much shorter than the longest one, transactions in it are not lost, but have continued to be present in the pending-transaction list associated with the longest chain, in those nodes which heard the original transaction broadcast. (I have also considered whether nodes should add transactions to their pending-transaction list that they learn about through blocks from other nodes, even if those blocks do not end up making their way into the longest block chain; but I'm not sure if that is necessary or helpful.)\nOnce these rules are clarified, more formal modeling will be helpful in understanding the behavior of the network given imperfect reliability. For example, if on average a fraction f of P2P nodes receive a given transaction broadcast, then I think one would expect 1/f block-creation times to elapse before the transaction appears in what is destined to become the longest chain. One might also ask, given that the P2P network broadcast is itself imperfectly reliable, how many candidate chains must a given node keep track of at one time, on average? Or as James raised earlier, if the network broadcast is reliable but depends on a potentially slow flooding algorithm, how does that impact performance?\nI am somewhat less worried about motivation. I'd be satisfied if the system can meet the following criteria:\n1. No single node operator, or small collection of node operators which controls only a small fraction of overall network resources,\ncan effectively cheat, if other players are honest.\n2. The long tail of node operators is sufficiently large that no small collection of nodes can control more than a small fraction of overall resources. (Here, the \"tail\" refers to a ranking based on amount of resources controlled by each operator.)\n3. The bitcoin system turns out to be socially useful and valuable, so that node operators feel that they are making a beneficial contribution to the world by their efforts (similar to the various \"@Home\" compute projects where people volunteer their compute resources for good causes).\nIn this case it seems to me that simple altruism can suffice to keep the network running properly.\nA very good point, and a more complete specification is necessary in order to understand how the network will respond to imperfections like this. I\nam looking forward to seeing more detail emerge.\nOne thing I might mention is that in many ways bitcoin is two independent ideas: a way of solving the kinds of problems James lists here, of creating a globally consistent but decentralized database; and then using it for a system similar to Wei Dai's b-money (which is referenced in the paper) but transaction/coin based rather than account based. Solving the global, massively decentralized database problem is arguably the harder part, as James emphasizes. The use of proof-of-work as a tool for this purpose is a novel idea well worth further review IMO.",
		"a": "Fortunately, it's only necessary to keep a pending-transaction pool for the current best branch. When a new block arrives for the best branch, ConnectBlock removes the block's transactions from the pending-tx pool. If a different branch becomes longer, it calls DisconnectBlock on the main branch down to the fork, returning the block transactions to the pending-tx pool, and calls ConnectBlock on the new branch, sopping back up any transactions that were in both branches. It's expected that reorgs like this would be rare and shallow.\nWith this optimisation, candidate branches are not really any burden. They just sit on the disk and don't require attention unless they ever become the main chain.\nBroadcasts will probably be almost completely reliable. TCP transmissions are rarely ever dropped these days, and the broadcast protocol has a retry mechanism to get the data from other nodes after a while. If broadcasts turn out to be slower in practice than expected, the target time between blocks may have to be increased to avoid wasting resources. We want blocks to usually propagate in much less time than it takes to generate them, otherwise nodes would spend too much time working on obsolete blocks.\nI'm planning to run an automated test with computers randomly sending payments to each other and randomly dropping packets.\nIt's very attractive to the libertarian viewpoint if we can explain it properly. I'm better with code than with words though."
	},
	{
		"date": "2008-11-15 04:43:00",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014858.html",
		"q": "Okay.... I'm going to summarize this protocol as I understand it.\nI'm filling in some operational details that aren't in the paper by supplementing what you wrote with what my own \"design sense\"\ntells me are critical missing bits or \"obvious\" methodologies for use.\nFirst, people spend computer power creating a pool of coins to use as money. Each coin is a proof-of-work meeting whatever criteria were in effect for money at the time it was created. The time of creation (and therefore the criteria) is checkable later because people can see the emergence of this particular coin in the transaction chain and track it through all its \"consensus view\"\nspends. (more later on coin creation tied to adding a link).\nWhen a coin is spent, the buyer and seller digitally sign a (blinded)\ntransaction record, and broadcast it to a bunch of nodes whose purpose is keeping track of consensus regarding coin ownership. If someone double spends, then the transaction record can be unblinded revealing the identity of the cheater. This is done via a fairly standard cut-\nand-choose algorithm where the buyer responds to several challenges with secret shares, and the seller then asks him to \"unblind\" and checks all but one, verifying that they do contain secret shares any two of which are sufficient to identify the buyer. In this case the seller accepts the unblinded spend record as \"probably\" containing a valid secret share.\nThe nodes keeping track of consensus regarding coin ownership are in a loop where they are all trying to \"add a link\" to the longest chain they've so far recieved. They have a pool of reported transactions which they've not yet seen in a \"consensus\" signed chain. I'm going to call this pool \"A\". They attempt to add a link to the chain by moving everything from pool A into a pool \"L\" and using a CPU-\nintensive digital signature algorithm to sign the chain including the new block L. This results in a chain extended by a block containing all the transaction records they had in pool L, plus the node's digital signature. While they do this, new transaction records continue to arrive and go into pool A again for the next cycle of work.\nThey may also recieve chains as long as the one they're trying to extend while they work, in which the last few \"links\" are links that are *not* in common with the chain on which they're working.\nThese they ignore. (? Do they ignore them? Under what circumstances would these become necessary to ever look at again,\nbearing in mind that any longer chain based on them will include them?)\nBut if they recieve a _longer_ chain while working, they immediately check all the transactions in the new links to make sure it contains no double spends and that the \"work factors\" of all new links are appropriate. If it contains a double spend,\nthen they create a \"transaction\" which is a proof of double spending, add it to their pool A, broadcast it, and continue work.\nIf one of the \"new\" links has an inappropriate work factor (ie,\nsomeone didn't put enough CPU into it for it to be \"licit\"\naccording to the rules) a new \"transaction\" which is a proof of the protocol violation by the link-creating node is created,\nbroadcast, and added to pool A, and the chain is rejected. In the case of no double spends and appropriate work factors for all links not yet seen, they accept the new chain as consensus.\nIf the new chain is accepted, then they give up on adding their current link, dump all the transactions from pool L back into pool\nA (along with transactions they've recieved or created since starting work), eliminate from pool A those transaction records which are already part of a link in the new chain, and start work again trying to extend the new chain.\nIf they complete work on a chain extended with their new link, they broadcast it and immediately start work on another new link with all the transactions that have accumulated in pool A since they began work.\nDo I understand it correctly?\nIs there a mechanism to make sure that the \"chain\" does not consist solely of links added by just the 3 or 4 fastest nodes? 'Cause a broadcast transaction record could easily miss those 3 or 4 nodes and if it does, and those nodes continue to dominate the chain, the transaction might never get added.\nTo remedy this, you need to either ensure provable propagation of transactions, or vary the work factor for a node depending on how many links have been added since that node's most recent link.\nUnfortunately, both measures can be defeated by sock puppets.\nThis is probably the worst problem with your protocol as it stands right now; you need some central point to control the identities (keys) of the nodes and prevent people from making new sock puppets.\nProvable propagation would mean that When Bob accepts a new chain from Alice, he needs to make sure that Alice has (or gets) all transactions in his \"A\" and \"L\" pools. He sends them, and\nAlice sends back a signed hash to prove she got them. Once\nAlice has recieved this block of transactions, if any subsequent chains including a link added by Alice do not include those transactions at or before that link, then Bob should be able to publish the block he sent Alice, along with her signature, in a transaction as proof that Alice violated protocol. Sock puppets defeat this because Alice just signs subsequent chains using a new key, pretending to be a different node.\nIf we go with varying the work factor depending on how many new links there are, then we're right back to domination by the 3 or 4 fastest nodes, except now they're joined by 600 or so sock puppets which they use to avoid the work factor penalty.\nIf we solve the sock-puppet issue, or accept that there's a central point controlling the generation of new keys, then generation of coins should be tied to the act of successfully adding a block to the \"consensus\" chain. This is simple to do; creation of a coin is a transaction, it gets added along with all the other transactions in the block. But you can only create one coin per link, and of course if your version of the chain isn't the one that gets accepted,\nthen in the \"accepted\" view you don't have the coin and can't spend it. This gives the people maintaining the consensus database a reason to spend CPU cycles, especially since the variance in work factor by number of links added since their own last link (outlined above) guarantees that everyone, not just the 3 or 4 fastest nodes,\noccasionally gets the opportunity to create a coin.\nAlso, the work requirement for adding a link to the chain should vary (again exponentially) with the number of links added to that chain in the previous week, causing the rate of coin generation\n(and therefore inflation) to be strictly controlled.\nYou need coin aggregation for this to scale. There needs to be a \"provable\" transaction where someone retires ten single coins and creates a new coin with denomination ten, etc. This is not too hard, using the same infrastructure you've already got; it simply becomes part of the chain, and when the chain is accepted consensus, then everybody can see that it happened.",
		"a": "I'll try and hurry up and release the sourcecode as soon as possible to serve as a reference to help clear up all these implementation questions.\nOnly the buyer signs, and there's no blinding.\nIdentities are not used, and there's no reliance on recourse. It's all prevention.\nNo challenges or secret shares. A basic transaction is just what you see in the figure in section 2. A signature (of the buyer) satisfying the public key of the previous transaction, and a new public key (of the seller) that must be satisfied to spend it the next time.\nRight, if it's equal in length, ties are broken by keeping the earliest one received.\nThere's no need for reporting of \"proof of double spending\" like that. If the same chain contains both spends, then the block is invalid and rejected.\nSame if a block didn't have enough proof-of-work. That block is invalid and rejected. There's no need to circulate a report about it. Every node could see that and reject it before relaying it.\nIf there are two competing chains, each containing a different version of the same transaction, with one trying to give money to one person and the other trying to give the same money to someone else, resolving which of the spends is valid is what the whole proof-of-work chain is about.\nWe're not \"on the lookout\" for double spends to sound the alarm and catch the cheater. We merely adjudicate which one of the spends is valid. Receivers of transactions must wait a few blocks to make sure that resolution has had time to complete. Would be cheaters can try and simultaneously double-spend all they want, and all they accomplish is that within a few blocks, one of the spends becomes valid and the others become invalid. Any later double-spends are immediately rejected once there's already a spend in the main chain.\nEven if an earlier spend wasn't in the chain yet, if it was already in all the nodes' pools, then the second spend would be turned away by all those nodes that already have the first spend.\nRight. They also refresh whenever a new transaction comes in, so L pretty much contains everything in A all the time.\nIt's a Hashcash style SHA-256 proof-of-work (partial pre-image of zero), not a signature.\nIf you're thinking of it as a CPU-intensive digital signing, then you may be thinking of a race to finish a long operation first and the fastest always winning.\nThe proof-of-work is a Hashcash style SHA-256 collision finding. It's a memoryless process where you do millions of hashes a second, with a small chance of finding one each time. The 3 or 4 fastest nodes' dominance would only be proportional to their share of the total CPU power. Anyone's chance of finding a solution at any time is proportional to their CPU power.\nThere will be transaction fees, so nodes will have an incentive to receive and include all the transactions they can. Nodes will eventually be compensated by transaction fees alone when the total coins created hits the pre-determined ceiling.\nRight.\nEvery transaction is one of these. Section 9, Combining and Splitting Value."
	},
	{
		"date": "2008-11-15 18:02:00",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014860.html",
		"q": "Okay, that's surprising. If you're not using buyer/seller identities, then you are not checking that a spend is being made by someone who actually is the owner of (on record as having recieved) the coin being spent.\nThere are three categories of identity that are useful to think about. Category one: public. Real-world identities are a matter of record and attached to every transaction.\nCategory two: Pseudonymous. There are persistent \"identities\"\nwithin the system and people can see if something was done by the same nym that did something else, but there's not necessarily any way of linking the nyms with real-world identities. Category three: unlinkably anonymous. There is no concept of identity,\npersistent or otherwise. No one can say or prove whether the agents involved in any transaction are the same agents as involved in any other transaction.\nAre you claiming category 3 as you seem to be, or category 2?\nLots of people don't distinguish between anonymous and pseudonymous protocols, so it's worth asking exactly what you mean here.\nAnyway: I'll proceed on the assumption that you meant very nearly (as nearly as I can imagine, anyway) what you said,\nunlinkably anonymous. That means that instead of an \"identity\",\na spender has to demonstrate knowledge of a secret known only to the real owner of the coin. One way to do this would be to have the person recieving the coin generate an asymmetric key pair, and then have half of it published with the transaction. In order to spend the coin later, s/he must demonstrate posession of the other half of the asymmetric key pair, probably by using it to sign the key provided by the new seller. So we cannot prove anything about \"identity\",\nbut we can prove that the spender of the coin is someone who knows a secret that the person who recieved the coin knows.\nNote, even though this doesn't involve identity per se, it still makes the agent doing the spend linkable to the agent who earlier recieved the coin, so these transactions are linkable.\nIn order to counteract this, the owner of the coin needs to make a transaction, indistinguishable to others from any normal transaction, in which he creates a new key pair and transfers the coin to its posessor (ie, has one sock puppet\n\"spend\" it to another). No change in real-world identity of the owner, but the transaction \"linkable\" to the agent who spent the coin is unlinked. For category-three unlinkability, this has to be done a random number of times - maybe one to six times?\nBTW, could you please learn to use carriage returns?? Your lines are scrolling stupidly off to the right and I have to scroll to see what the heck you're saying, then edit to add carriage returns before I respond.\nMmmm. I don't know if I'm comfortable with that. You're saying there's no effort to identify and exclude nodes that don't cooperate? I suspect this will lead to trouble and possible DOS\nattacks.\nOkay, when you say \"same\" transaction, and you're talking about transactions that are obviously different, you mean a double spend, right? Two transactions signed with the same key?\nUntil.... until what? How does anybody know when a transaction has become irrevocable? Is \"a few\" blocks three? Thirty? A\nhundred? Does it depend on the number of nodes? Is it logarithmic or linear in number of nodes?\nBut in the absence of identity, there's no downside to them if spends become invalid, if they've already recieved the goods they double-spent for (access to website, download,\nwhatever). The merchants are left holding the bag with\n\"invalid\" coins, unless they wait that magical \"few blocks\"\n(and how can they know how many?) before treating the spender as having paid.\nThe consumers won't do this if they spend their coin and it takes an hour to clear before they can do what they spent their coin on.\nThe merchants won't do it if there's no way to charge back a customer when they find the that their coin is invalid because the customer has doublespent.\nSo there's a possibility of an early catch when the broadcasts of the initial simultaneous spends interfere with each other. I assume here that the broadcasts are done by the sellers, since the buyer has a possible disincentive to broadly disseminate spends.\nOkay, that's a big difference between a proof of work that takes a huge set number of CPU cycles and a proof of work that takes a tiny number of CPU cycles but has a tiny chance of success. You can change the data set while working, and it doesn't mean you need to start over. This is good in this case, as it means nobody has to hold recently recieved transactions out of the link they're working on.\nRight. That was the misconception I was working with. Again, the difference between a proof taking a huge set number of CPU cycles and a proof that takes a tiny number of CPU cycles but has a tiny chance of success.\nIt's like a random variation in the work factor; in this way it works in your favor.\nI don't understand how \"transaction fees\" would work, and how the money would find its way from the agents doing transactions to those running the network. But the economic effect is the same (albeit somewhat randomized) if adding a link to the chain allows the node to create a coin, so I would stick with that.\nAlso, be aware that the compute power of different nodes can be expected to vary by two orders of magnitude at any given moment in history.",
		"a": "Right, it's ECC digital signatures. A new key pair is used for every transaction.\nIt's not pseudonymous in the sense of nyms identifying people, but it is at least a little pseudonymous in that the next action on a coin can be identified as being from the owner of that coin.\nThere is no reliance on identifying anyone. As you've said, it's futile and can be trivially defeated with sock puppets.\nThe credential that establishes someone as real is the ability to supply CPU power.\nSection 11 calculates the worst case under attack. Typically, 5 or 10 blocks is enough for that. If you're selling something that doesn't merit a network-scale attack to steal it, in practice you could cut it closer.\nThis is a version 2 problem that I believe can be solved fairly satisfactorily for most applications.\nThe race is to spread your transaction on the network first. Think 6 degrees of freedom -- it spreads exponentially. It would only take something like 2 minutes for a transaction to spread widely enough that a competitor starting late would have little chance of grabbing very many nodes before the first one is overtaking the whole network.\nDuring those 2 minutes, the merchant's nodes can be watching for a double-spent transaction. The double-spender would not be able to blast his alternate transaction out to the world without the merchant getting it, so he has to wait before starting.\nIf the real transaction reaches 90% and the double-spent tx reaches 10%, the double-spender only gets a 10% chance of not paying, and 90%\nchance his money gets spent. For almost any type of goods, that's not going to be worth it for the scammer.\nInformation based goods like access to website or downloads are non-fencible. Nobody is going to be able to make a living off stealing access to websites or downloads. They can go to the file sharing networks to steal that. Most instant-access products aren't going to have a huge incentive to steal.\nIf a merchant actually has a problem with theft, they can make the customer wait 2 minutes, or wait for something in e-mail, which many already do. If they really want to optimize, and it's a large download, they could cancel the download in the middle if the transaction comes back double-spent. If it's website access,\ntypically it wouldn't be a big deal to let the customer have access for 5 minutes and then cut off access if it's rejected. Many such sites have a free trial anyway."
	},
	{
		"date": "2008-11-17 17:24:43",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2008-November/014863.html",
		"q": "This requires that we know, that is to say an honest well behaved peer whose communications and data storage is working well knows, what the current best branch is -\nbut of course, the problem is that we are trying to discover, trying to converge upon, a best branch, which is not easy at the best of times, and becomes harder when another peer is lying about its connectivity and capabilities, and yet another peer has just had a major disk drive failure obfuscated by a software crash, and the international fibers connecting yet a third peer have been attacked by terrorists.\nWhich presupposes the branches exist, that they are fully specified and complete. If they exist as complete works, rather than works in progress, then the problem is already solved, for the problem is making progress.\nThere is a trade off between timeliness and reliability.\nOne can make a broadcast arbitrarily reliable if time is of no consequence. However, when one is talking of distributed data, time is always of consequence, because it is all about synchronization (that peers need to have corresponding views at corresponding times) so when one does distributed data processing, broadcasts are always highly unreliable Attempts to ensure that each message arrives at least once result in increased timing variation. Thus one has to make a protocol that is either UDP or somewhat UDP like, in that messages are small, failure of messages to arrive is common, messages can arrive in different order to the order in which they were sent, and the same message may arrive multiple times. Either we have UDP, or we need to accommodate the same problems as UDP has on top of TCP connections.\nRather than assuming that each message arrives at least once, we have to make a mechanism such that the information arrives even though conveyed by messages that frequently fail to arrive.\nPeople always load connections near maximum. When a connection is near maximum, TCP connections suffer frequent unreasonably long delays, and connections simply fail a lot - your favorite web cartoon somehow shows it is loading forever, and you try again, or it comes up with a little x in place of a picture, and you try again\nFurther very long connections - for example ftp downloads of huge files, seldom complete. If you try to ftp a movie, you are unlikely to get anywhere unless both client and server have a resume mechanism so that they can talk about partially downloaded files.\nUDP connections, for example Skype video calls, also suffer frequent picture freezes, loss of quality, and so forth, and have to have mechanisms to keep going regardless.\nNo, it is very attractive to the libertarian if we can design a mechanism that will scale to the point of providing the benefits of rapidly irreversible payment,\nimmune to political interference, over the internet,\nto very large numbers of people. You have an outline and proposal for such a design, which is a big step forward, but the devil is in the little details.\nI really should provide a fleshed out version of your proposal, rather than nagging you to fill out the blind",
		"a": "I mean a node only needs the pending-tx pool for the best branch it has. The branch that it currently thinks is the best branch.\nThat's the branch it'll be trying to make a block out of, which is all it needs the pool for.\nI think I've got the peer networking broadcast mechanism covered.\nEach node sends its neighbours an inventory list of hashes of the new blocks and transactions it has. The neighbours request the items they don't have yet. If the item never comes through after a timeout, they request it from another neighbour that had it. Since all or most of the neighbours should eventually have each item,\neven if the coms get fumbled up with one, they can get it from any of the others, trying one at a time.\nThe inventory-request-data scheme introduces a little latency, but it ultimately helps speed more by keeping extra data blocks off the transmit queues and conserving bandwidth.\nI believe I've worked through all those little details over the last year and a half while coding it, and there were a lot of them.\nThe functional details are not covered in the paper, but the sourcecode is coming soon. I sent you the main files.\n(available by request at the moment, full release soon)"
	},
	{
		"date": "2009-01-16 16:03:14",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2009-January/015014.html",
		"q": "Announcing the first release of Bitcoin, a new electronic cash system that uses a peer-to-peer network to prevent double-spending.\nIt's completely decentralized with no server or central authority.\nSee bitcoin.org for screenshots.\nhttp://downloads.sourceforge.net/bitcoin/bitcoin-0.1.0.rar\nWindows only for now. Open source C++ code is included.\n- Unpack the files into a directory\n- Run BITCOIN.EXE\n- It automatically connects to other nodes\nIf you can keep a node running that accepts incoming connections,\nyou'll really be helping the network a lot. Port 8333 on your firewall needs to be open to receive incoming connections.\nThe software is still alpha and experimental. There's no guarantee the system's state won't have to be restarted at some point if it becomes necessary, although I've done everything I can to build in extensibility and versioning.\nYou can get coins by getting someone to send you some, or turn on\nOptions->Generate Coins to run a node and generate blocks. I made the proof-of-work difficulty ridiculously easy to start with, so for a little while in the beginning a typical PC will be able to generate coins in just a few hours. It'll get a lot harder when competition makes the automatic adjustment drive up the difficulty.\nGenerated coins must wait 120 blocks to mature before they can be spent.\nThere are two ways to send money. If the recipient is online, you can enter their IP address and it will connect, get a new public key and send the transaction with comments. If the recipient is not online, it is possible to send to their Bitcoin address, which is a hash of their public key that they give you. They'll receive the transaction the next time they connect and get the block it's in. This method has the disadvantage that no comment information is sent, and a bit of privacy may be lost if the address is used multiple times, but it is a useful alternative if both users can't be online at the same time or the recipient can't receive incoming connections.\nTotal circulation will be 21,000,000 coins. It'll be distributed to network nodes when they make blocks, with the amount cut in half every 4 years.\nfirst 4 years: 10,500,000 coins next 4 years: 5,250,000 coins next 4 years: 2,625,000 coins next 4 years: 1,312,500 coins etc...\nWhen that runs out, the system can support transaction fees if needed. It's based on open market competition, and there will probably always be nodes willing to process transactions for free.",
		"a": "I would be surprised if 10 years from now we're not using electronic currency in some way, now that we know a way to do it that won't inevitably get dumbed down when the trusted third party gets cold feet.\nIt could get started in a narrow niche like reward points,\ndonation tokens, currency for a game or micropayments for adult sites. Initially it can be used in proof-of-work applications for services that could almost be free but not quite.\nIt can already be used for pay-to-send e-mail. The send dialog is resizeable and you can enter as long of a message as you like.\nIt's sent directly when it connects. The recipient doubleclicks on the transaction to see the full message. If someone famous is getting more e-mail than they can read, but would still like to have a way for fans to contact them, they could set up Bitcoin and give out the IP address on their website. \"Send X bitcoins to my priority hotline at this IP and I'll read the message personally.\"\nSubscription sites that need some extra proof-of-work for their free trial so it doesn't cannibalize subscriptions could charge bitcoins for the trial.\nIt might make sense just to get some in case it catches on. If enough people think the same way, that becomes a self fulfilling prophecy. Once it gets bootstrapped, there are so many applications if you could effortlessly pay a few cents to a website as easily as dropping coins in a vending machine.\nSatoshi Nakamoto"
	},
	{
		"date": "2009-01-25 15:47:10",
		"src": "http://www.metzdowd.com/pipermail/cryptography/2009-January/015041.html",
		"q": "Certainly a valid point, and one which has been widely discussed in the debates over the years about electronic cash. Bitcoin has a couple of things going for it: one is that it is distributed, with no single point of failure, no \"mint\", no company with officers that can be subpoenaed and arrested and shut down. It is more like a P2P network,\nand as we have seen, despite degrees of at least governmental distaste,\nthose are still around.\nBitcoin could also conceivably operate in a less anonymous mode, with transfers being linked to individuals, rather than single-use keys. It would still be useful to have a large scale, decentralized electronic payment system.\nIt also might be possible to refactor and restructure Bitcoin to separate out the key new idea, a decentralized, global, irreversible transaction database. Such a functionality might be useful for other purposes. Once it exists, using it to record monetary transfers would be a sort of side effect and might be harder to shut down.\nIt's important to understand that the proof-of-work (POW) aspect of\nBitcoin is primarily oriented around ensuring the soundness of the historical transaction database. Each Bitcoin data block records a set of transactions, and includes a hash collision. Subsequent data blocks have their own transactions, their own collisions, and also chain to all earlier hashes. The result is that once a block is \"buried\" under enough new blocks, it is essentially certain (given the threat model,\nnamely that attackers cannot muster more than X% of the compute power of legitimate node operators) that old transactions can't be reversed.\nCreating new coins is indeed currently also being done by POW, but I\nthink that is seen as a temporary expedient, and in fact the current software phases that out over several years. Hence worries about botnets being able to manufacture large quantities of POW tokens are only a temporary concern, in the context of Bitcoin.\nThere have been a number of discussions in the past about POW tokens as anti spam measures, given the botnet threat. References are available from\n\"Proof-of-work system\" on Wikipedia. Analyses have yielded mixed results,\ndepending on the assumptions and system design.\nIf POW tokens do become useful, and especially if they become money,\nmachines will no longer sit idle. Users will expect their computers to be earning them money (assuming the reward is greater than the cost to operate). A computer whose earnings are being stolen by a botnet will be more noticeable to its owner than is the case today, hence we might expect that in that world, users will work harder to maintain their computers and clean them of botnet infestations.\nCountermeasures by botnet operators would include moderating their take,\nperhaps only stealing 10% of the productive capacity of invaded computers,\nso that their owners would be unlikely to notice. This kind of thinking quickly degenerates into unreliable speculation, but it points out the difficulties of analyzing the full ramifications of a world where POW\ntokens are valuble.",
		"a": "there would be a profit motive for people to set up massive quantities of fake e-mail accounts to harvest POW tokens from spam. They'd essentially be reverse-spamming the spammers with automated mailboxes that collect their POW and don't read the message. The ratio of fake mailboxes to real people could become too high for spam to be cost effective.\nThe process has the potential to establish the POW token's value in the first place, since spammers that don't have a botnet could buy tokens from harvesters. While the buying back would temporarily let more spam through, it would only hasten the self-defeating cycle leading to too many harvesters exploiting the spammers.\nInterestingly, one of the e-gold systems already has a form of spam called \"dusting\". Spammers send a tiny amount of gold dust in order to put a spam message in the transaction's comment field.\nIf the system let users configure the minimum payment they're willing to receive, or at least the minimum that can have a message with it, users could set how much they're willing to get paid to receive spam."
	},
	{
		"date": "2009-01-25 16:45:25",
		"src": "https://sourceforge.net/p/bitcoin/mailman/message/21424626/",
		"q": "I have had a couple of problems running bitcoin: is this an appropriate list for reporting them (with about 70kb of attachments)?\nNicholas Bohm\n--\nSalkyns, Great Canfield, Takeley,\nBishop's Stortford CM22 6SX, UK\nPhone 01279 870285 (+44 1279 870285)\nMobile 07715 419728 (+44 7715 419728)\nPGP public key ID: 0x899DD7FF. Fingerprint:\n5248 1320 B42E 84FC 1E8B A9E6 0912 AE66 899D D7FF",
		"a": "From: Nicholas Bohm 2009-01-25 10:17\nWhat's the problem you're having?\nIf you send me your debug.log file directly (best not to send attachments to the list), I can take a look at what's happening.\nSatoshi Nakamoto bitcoin-help at vistomail dot com"
	},
	{
		"date": "2009-02-22 17:47:52",
		"src": "https://sourceforge.net/p/bitcoin/mailman/message/21646307/",
		"q": "Version 0.1.5 seems to be running trouble free. I have a list of 201 transactions, I've accumulated about bc8550. Transfers in and out seem to work fine (after a bit of head-scratching to understand the labelling of incoming transactions).\nWhat's next?\nNicholas Bohm\n--\nSalkyns, Great Canfield, Takeley,\nBishop's Stortford CM22 6SX, UK\nPhone 01279 870285 (+44 1279 870285)\nMobile 07715 419728 (+44 7715 419728)\nPGP public key ID: 0x899DD7FF. Fingerprint:\n5248 1320 B42E 84FC 1E8B A9E6 0912 AE66 899D D7FF",
		"a": "The next thing for v0.1.6 is to take advantage of multiple processors to generate blocks. Currently it only starts one thread. If you have a multi-core processor like a Core Duo or\nQuad this will double or quadruple your production.\nLater I want to add interfaces to make it really easy to integrate into websites from any server side language.\nSatoshi http://www.bitcoin.org"
	},
	{
		"date": "2009-03-04 16:59:12",
		"src": "https://sourceforge.net/p/bitcoin/mailman/message/21740046/",
		"q": "That sounds good. I'd also like to be able to run multiple coin/block generators on multiple machines, all behind a single NAT address. I\nhaven't tried this yet so I don't know if it works on the current software.\nBTW I don't remember if we talked about this, but the other day some people were mentioning secure timestamping. You want to be able to prove that a certain document existed at a certain time in the past.\nSeems to me that bitcoin's stack of blocks would be perfect for this.\nRight, and I'd like to see more of a library interface that could be called from programming or scripting languages, on the client side as well.\nHal",
		"a": "The current version will work fine. They'll each connect over the\nInternet, while incoming connections only come to the host that port 8333 is routed to.\nAs an optimisation, I'll make a switch \"-connect=1.2.3.4\" to make it only connect to a specific address. You could make your extra nodes connect to your primary, and only the primary connects over the Internet. It doesn't really matter for now, since the network would have to get huge before the bandwidth is anything more than trivial.\nIndeed, Bitcoin is a distributed secure timestamp server for transactions. A few lines of code could create a transaction with an extra hash in it of anything that needs to be timestamped.\nI should add a command to timestamp a file that way.\nExactly.\nSatoshi Nakamoto http://www.bitcoin.org"
	},
	{
		"date": "2009-10-23 23:57:51",
		"src": "https://sourceforge.net/p/bitcoin/mailman/message/23824064/",
		"q": "Do you Windows users experience occasional Bitcoin crashes?\nLately Bitcoin running in wine-1.0.1 has been crashing frequently. I was just wondering whether this is a Wine issue or a Bitcoin issue. I speculate it might have something to do with how many Bitcoins I have since it would crash less when I had less bitcoins and now crashes more now that I have more bitcoins. It makes me hesitant to send my balance of bitcoins to my fresh Bitcoin installation. But this might just be my imagination since it has crashed a few times after installing Bitcoin afresh.\nThe following four lines print from the terminal when I start Bitcoin.\nfixme:toolhelp:CreateToolhelp32Snapshot Unimplemented: heap list snapshot fixme:toolhelp:Heap32ListFirst : stub fixme:toolhelp:CreateToolhelp32Snapshot Unimplemented: heap list snapshot fixme:toolhelp:Heap32ListFirst : stub\nI previously wasn't starting Bitcoin from the terminal, so I don't know what gets printed out when it crashes, but I'll reply with the results the next time it crashes.\nWhile Bitcoin first downloads previously completed blocks, the file debug.log grows grows to 17.4 MB and then stops growing. I imagine it will continue to grow as more bitcoins are completed.\n~NewLibertyStandard~",
		"a": "I haven't had any reports of crashes in v0.1.5. It's been rock solid for me on Windows. I think it must be Wine related. If you get another crash in Wine and it prints anything on the terminal, e-mail me and I\nmay be able to figure out what happened, maybe something I can work around. Martti and I have been working on a new version to release soon and it would be nice to get any Wine fixes in there.\nThose don't look like anything to worry about. Probably functions unimplemented by Wine that are harmlessly stubbed out.\nYou can delete debug.log occasionally if you don't want to take the disk space. It's just status messages that help with debugging.\nbitcoin.sourceforge.net looks fine now. Maybe sourceforge was doing some maintenance.\nSatoshi"
	}
]